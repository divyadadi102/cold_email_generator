import os
from langchain_groq import ChatGroq
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.exceptions import OutputParserException
from dotenv import load_dotenv

load_dotenv()

class Chain:
    def __init__(self):
        self.llm = ChatGroq(temperature=0, groq_api_key=os.getenv("GROQ_API_KEY"), model_name="llama-3.3-70b-versatile")

    def extract_jobs(self, cleaned_text):
        prompt_extract = PromptTemplate.from_template(
            """
            ### SCRAPED TEXT FROM WEBSITE:
            {page_data}
            ### INSTRUCTION:
            The scraped text is from the career's page of a website.
            Your job is to extract the job postings and return them in JSON format containing the following keys: `role`, `experience`, `skills`, and `description`.
            Only return the valid JSON.
            ### VALID JSON (NO PREAMBLE):
            """
        )
        chain_extract = prompt_extract | self.llm
        res = chain_extract.invoke(input={"page_data": cleaned_text})
        try:
            json_parser = JsonOutputParser()
            res = json_parser.parse(res.content)
        except OutputParserException:
            raise OutputParserException("Context too big. Unable to parse jobs.")
        return res if isinstance(res, list) else [res]

    def write_mail(self, job, links):
        prompt_email = PromptTemplate.from_template(
            """
            ### JOB DESCRIPTION:
            {job_description}

            ### INSTRUCTION:
            You are Divya Dadi, a Master of Computer Science student at Rice University with internship experience as a Software Engineer at Walmart Global Tech and a Junior Data Engineer at Tata Consultancy Services. 
            At Walmart Global Tech, I processed large datasets using Scala and Apache Spark, ensuring high performance and scalability. I also designed and implemented automated data pipelines with Apache Airflow, ensuring timely availability of critical data. 
            Additionally, I leveraged GCP services, such as BigQuery and Google Cloud Storage, for efficient data storage and retrieval. 
            Your job is to write a cold email to the hiring manager describing and highlighting your skills and experiences that align with the job requirements. 
            Remember you are Divya Dadi, a student and candidate for the position.
            Include link to Divya's LinkedIn: https://www.linkedin.com/in/divya-dadi-9a2539172/, email id dd80@rice.edu
            ### EMAIL (NO PREAMBLE):
            """
        )
        chain_email = prompt_email | self.llm
        res = chain_email.invoke({"job_description": str(job), "link_list": links})
        return res.content

if __name__ == "__main__":
    print(os.getenv("GROQ_API_KEY"))

