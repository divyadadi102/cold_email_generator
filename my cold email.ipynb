{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5bad1c84-7385-494d-bf19-603c5e1b7787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Software Engineer II - Workday Integration, ITC at NIKE, INC.\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am excited to apply for the Software Engineer II - Workday Integration, ITC role at NIKE, INC. As a Master of Computer Science student at Rice University with a strong background in software engineering and data analysis, I am confident that my skills and experiences align with the job requirements.\n",
      "\n",
      "With over 2 years of experience in software engineering and data analysis, I have developed a strong foundation in object-oriented concepts, which I believe is essential for this role. My experience with Scala and Apache Spark has taught me the importance of high performance and scalability in software development. Additionally, my experience with Apache Airflow has given me a deep understanding of automated data pipelines and timely data availability.\n",
      "\n",
      "Although I don't have direct experience with Workday Studio, EIB, Core Connectors, and payroll connectors (PECI), I am eager to learn and apply my skills in a new context. My experience with XML, XSLT, and Web Services (WSDL, SOAP) has given me a solid understanding of data integration and exchange. I am also familiar with SaaS applications, SaaS deployment models, and SaaS DevOps, which I believe is essential for this role.\n",
      "\n",
      "As a detail-oriented and analytical person, I have a strong passion for data analysis and visualization. My experience with Tableau has given me the ability to develop comprehensive dashboards, providing valuable insights and supporting data-driven decision-making.\n",
      "\n",
      "I am particularly drawn to this role because of the opportunity to work with HR Services and Operations and support Workday Integration solutions for Core HR Shared Services, Payroll, Total Rewards Operations, Talent Operations, Talent Acquisition, and Learning & Development. I am excited about the prospect of working with a talented team and contributing to the success of NIKE, INC.\n",
      "\n",
      "I would welcome the opportunity to discuss my application and how my skills and experiences align with the job requirements. Please feel free to contact me at your convenience.\n",
      "\n",
      "You can also connect with me on LinkedIn: https://www.linkedin.com/in/divya-dadi-9a2539172/\n",
      "\n",
      "Thank you for considering my application. I look forward to the opportunity to discuss this further.\n",
      "\n",
      "Best regards,\n",
      "\n",
      "Divya Dadi\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    temperature=0,\n",
    "    groq_api_key=\"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\",\n",
    "    model=\"llama-3.1-70b-versatile\"\n",
    ")\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://jobs.nike.com/job/R-39383\")\n",
    "page_data = loader.load().pop().page_content\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### SCRAPED TEXT FROM WEBSITE:\n",
    "        {page_data}\n",
    "        ### INSTRUCTION:\n",
    "        The scraped text is from the career's page of a website.\n",
    "        Your job is to extract the job postings and return them in JSON format containing the \n",
    "        following keys:`company name`,`role`, `experience`, `skills` and `description`.\n",
    "        Only return the valid JSON.\n",
    "        ### VALID JSON (NO PREAMBLE):    \n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "chain_extract = prompt_extract | llm \n",
    "res = chain_extract.invoke(input={'page_data':page_data})\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "json_parser = JsonOutputParser()\n",
    "json_res = json_parser.parse(res.content)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"roles.csv\")\n",
    "\n",
    "import uuid\n",
    "for _, row in df.iterrows():\n",
    "    collection.add(documents=row[\"Techstack\"],\n",
    "        metadatas={\"links\": row[\"Links\"]}, ids=[str(uuid.uuid4())])\n",
    "\n",
    "# Use extracted skills from json_res\n",
    "job = json_res\n",
    "\n",
    "# Check if 'skills' key exists in the job and is not empty\n",
    "if 'skills' in job and job['skills']:\n",
    "    links = collection.query(query_texts=job['skills'], n_results=2).get('metadatas', [])\n",
    "else:\n",
    "    links = []  # Handle case where no skills are available\n",
    "\n",
    "prompt_email = PromptTemplate.from_template(\n",
    "        \"\"\"\n",
    "        ### JOB DESCRIPTION:\n",
    "        {job_description}\n",
    "        \n",
    "        ### INSTRUCTION:\n",
    "        You are Divya Dadi, a Master of Computer Science student at Rice University with internship experience as a Software Engineer at Walmart Global Tech and a Junior Data Analyst at Tata Consultancy Services. \n",
    "        At Walmart Global Tech, I processed large datasets using Scala and Apache Spark, ensuring high performance and scalability. I also designed and implemented automated data pipelines with Apache Airflow, ensuring timely availability of critical data. \n",
    "        Additionally, I leveraged GCP services, such as BigQuery and Google Cloud Storage, for efficient data storage and retrieval.I collaborated closely with cross-functional teams to maintain data accuracy and integrity. Furthermore, I developed comprehensive Tableau dashboards, providing valuable insights and supporting data-driven decision-making across the organization.\n",
    "        Your job is to write a cold email to the hiring manager regarding the above-mentioned job, describing your skills and experiences that align with the job requirements. Don't involve any other links.\n",
    "        Remember you are Divya Dadi, a student and a candidate for the position. Please include link to my LinkedIn: https://www.linkedin.com/in/divya-dadi-9a2539172/\n",
    "        ### EMAIL (NO PREAMBLE):\n",
    "        \n",
    "        \"\"\"\n",
    ")\n",
    "\n",
    "chain_email = prompt_email | llm\n",
    "res = chain_email.invoke({\"job_description\": str(job), \"link_list\": links})\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "84e2195b-c6dd-4efd-b563-549989f02ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Application for Software Engineer II - Workday Integration, ITC at NIKE, INC.\n",
      "\n",
      "Dear Hiring Manager,\n",
      "\n",
      "I am excited to apply for the Software Engineer II - Workday Integration, ITC position at NIKE, INC. As a Master of Computer Science student at Rice University with a strong background in software engineering and data engineering, I am confident that my skills and experiences align with the job requirements.\n",
      "\n",
      "With over 2 years of experience in software engineering and data engineering, I have developed a strong foundation in object-oriented concepts, which I believe is essential for this role. My experience as a Software Engineer at Walmart Global Tech has provided me with hands-on experience in designing and implementing automated data pipelines using Apache Airflow, ensuring timely availability of critical data. Additionally, I have leveraged GCP services, such as BigQuery and Google Cloud Storage, for efficient data storage and retrieval.\n",
      "\n",
      "Although I don't have direct experience with Workday Studio, EIB, Core Connectors, and payroll connectors (PECI), I am confident that my experience with XML, XSLT, and Web Services (WSDL, SOAP) will enable me to quickly learn and adapt to the Workday Integration platform. My experience with SaaS applications, SaaS deployment models, and SaaS DevOps will also be beneficial in this role.\n",
      "\n",
      "As a detail-oriented and analytical individual, I have a proven track record of collaborating closely with cross-functional teams to maintain data accuracy and integrity. My experience in developing comprehensive Tableau dashboards has provided me with the skills to provide valuable insights and support data-driven decision-making across the organization.\n",
      "\n",
      "I am particularly drawn to this role because of the opportunity to work with HR Technology Engineering and support Workday Integration solutions for Core HR Shared Services, Payroll, Total Rewards Operations, Talent Operations, Talent Acquisition, and Learning & Development. I am excited about the prospect of working with a talented team to design and implement innovative solutions that drive business outcomes.\n",
      "\n",
      "Thank you for considering my application. I would welcome the opportunity to discuss my qualifications further and explain in greater detail why I am the ideal candidate for this role. Please feel free to connect with me on LinkedIn: https://www.linkedin.com/in/divya-dadi-9a2539172/.\n",
      "\n",
      "Sincerely,\n",
      "Divya Dadi\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries and modules\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "import pandas as pd\n",
    "import uuid\n",
    "\n",
    "# Step 1: Initialize the LLM (ChatGroq) with specific model and API key\n",
    "llm = ChatGroq(\n",
    "    temperature=0,  # Set temperature for response randomness\n",
    "    groq_api_key=\"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\",  # API key for authentication\n",
    "    model=\"llama-3.1-70b-versatile\"  # The specific LLM model to use\n",
    ")\n",
    "\n",
    "# Step 2: Load the webpage data from the specified URL (Nike job page)\n",
    "loader = WebBaseLoader(\"https://jobs.nike.com/job/R-39383\")\n",
    "page_data = loader.load().pop().page_content  # Get the content from the loaded page\n",
    "\n",
    "# Step 3: Define the prompt template to extract job postings in JSON format\n",
    "prompt_extract = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ### SCRAPED TEXT FROM WEBSITE:\n",
    "    {page_data}\n",
    "    \n",
    "    ### INSTRUCTION:\n",
    "    The scraped text is from the career's page of a website.\n",
    "    Your job is to extract the job postings and return them in JSON format containing the \n",
    "    following keys:`company name`,`role`, `experience`, `skills` and `description`.\n",
    "    Only return the valid JSON.\n",
    "    ### VALID JSON (NO PREAMBLE):    \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Step 4: Run the extraction chain to get job postings in JSON format\n",
    "chain_extract = prompt_extract | llm \n",
    "res = chain_extract.invoke(input={'page_data': page_data})\n",
    "\n",
    "# Step 5: Parse the extracted response into valid JSON\n",
    "json_parser = JsonOutputParser()\n",
    "json_res = json_parser.parse(res.content)  # Convert the LLM output into a JSON object\n",
    "\n",
    "# Step 6: Load roles.csv for tech stack data (techstack and links)\n",
    "df = pd.read_csv(\"roles.csv\")  # Read CSV file into a pandas DataFrame\n",
    "\n",
    "# Step 7: (Optional) Add data from the CSV to ChromaDB collection (for advanced querying)\n",
    "client = chromadb.PersistentClient('vectorstore')  # Initialize ChromaDB client\n",
    "collection = client.get_or_create_collection(name=\"portfolio\")  # Create or get existing collection\n",
    "\n",
    "# Add rows from CSV into the ChromaDB collection\n",
    "for _, row in df.iterrows():\n",
    "    collection.add(documents=row[\"Techstack\"],\n",
    "                   metadatas={\"links\": row[\"Links\"]}, \n",
    "                   ids=[str(uuid.uuid4())])  # Add rows to the collection\n",
    "\n",
    "# Step 8: Use the extracted skills from the JSON result to query ChromaDB\n",
    "job = json_res  # Assign parsed job details from the JSON result\n",
    "\n",
    "# Check if 'skills' key exists in the job and fetch relevant links from ChromaDB\n",
    "if 'skills' in job and job['skills']:\n",
    "    links = collection.query(query_texts=job['skills'], n_results=2).get('metadatas', [])\n",
    "else:\n",
    "    links = []  # Handle the case where no skills are available or 'skills' key is missing\n",
    "\n",
    "# Step 9: Define the email prompt template using job description and links\n",
    "prompt_email = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    ### JOB DESCRIPTION:\n",
    "    {job_description}\n",
    "    \n",
    "    ### INSTRUCTION:\n",
    "    You are Divya Dadi, a Master of Computer Science student at Rice University with internship experience as a Software Engineer at Walmart Global Tech and a Junior Data Engineer at Tata Consultancy Services. \n",
    "    At Walmart Global Tech, I processed large datasets using Scala and Apache Spark, ensuring high performance and scalability. I also designed and implemented automated data pipelines with Apache Airflow, ensuring timely availability of critical data. \n",
    "    Additionally, I leveraged GCP services, such as BigQuery and Google Cloud Storage, for efficient data storage and retrieval.I collaborated closely with cross-functional teams to maintain data accuracy and integrity. Furthermore, I developed comprehensive Tableau dashboards, providing valuable insights and supporting data-driven decision-making across the organization.\n",
    "    \n",
    "    Your job is to write a cover letter to the hiring manager regarding the above-mentioned job, describing your skills and experiences that align with the job requirements. Don't involve any other links.\n",
    "    Remember you are Divya Dadi, a student and a candidate for the position. Please include link to my LinkedIn: https://www.linkedin.com/in/divya-dadi-9a2539172/. \n",
    "    \n",
    "    ### EMAIL (NO PREAMBLE):\n",
    "    \n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# Step 10: Generate the email using the LLM and the job description\n",
    "chain_email = prompt_email | llm\n",
    "res = chain_email.invoke({\"job_description\": str(job), \"link_list\": links})\n",
    "\n",
    "# Step 11: Output the generated email content\n",
    "print(res.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
